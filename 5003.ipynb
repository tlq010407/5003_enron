{"cells":[{"cell_type":"markdown","metadata":{},"source":["Download the enron dataset"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Downloading the Enron dataset (this may take a while)\n","To check on progress, you can cd up one level, then execute <ls -lthr>\n","Enron dataset should be last item on the list, along with its current size\n","Download will complete at about 1.82 GB\n"]}],"source":["print(\"Downloading the Enron dataset (this may take a while)\")\n","print(\"To check on progress, you can cd up one level, then execute <ls -lthr>\")\n","print(\"Enron dataset should be last item on the list, along with its current size\")\n","print(\"Download will complete at about 1.82 GB\")\n","\n","import requests\n","url = \"https://www.cs.cmu.edu/~./enron/enron_mail_20150507.tar.gz\"\n","filename = \"../enron_mail_20150507.tar.gz\"\n","with open(filename, \"wb\") as f:\n","    r = requests.get(url)\n","    f.write(r.content)\n","print(\"Download Complete!\")\n","\n","print(\"Unzipping Enron dataset (This may take a while)\")\n","import tarfile\n","tfile = tarfile.open(\"../enron_mail_20150507.tar.gz\")\n","tfile.extractall(\".\")\n","tfile.close()\n","\n","print(\"You're ready to go!\")"]},{"cell_type":"markdown","metadata":{},"source":["Convert all enron email files to csv"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["import os\n","import csv"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["# Define the root directory of the Enron dataset\n","MAILDIR_PATH = \"./maildir\" \n","OUTPUT_CSV = \"enron_emails.csv\""]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[],"source":["# Define the CSV columns\n","fields = [\"file\", \"message\"]"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Emails have been successfully written to enron_emails.csv\n"]}],"source":["# Function to extract email content from a file\n","def extract_email(file_path):\n","    with open(file_path, \"r\", encoding=\"latin1\") as file:\n","        data = file.read()\n","    relative_path = os.path.relpath(file_path, MAILDIR_PATH).replace(MAILDIR_PATH + '/', '')\n","    email_message = email.message_from_string(data)\n","    return {\n","        \"file\": relative_path,\n","        \"message\": email_message.as_string()\n","    }\n","\n","# List to store the email data\n","all_emails = []\n","\n","# Walk through the directories and extract emails\n","for root, dirs, files in os.walk(MAILDIR_PATH):\n","    for file in files:\n","        file_path = os.path.join(root, file)\n","        try:\n","            email_content = extract_email(file_path)\n","            all_emails.append(email_content)\n","        except Exception as e:\n","            print(f\"Failed to extract {file_path}: {e}\")\n","\n","# Write the emails to a CSV file\n","with open(OUTPUT_CSV, \"w\", newline=\"\", encoding=\"utf-8\") as csv_file:\n","    csv_writer = csv.DictWriter(csv_file, fieldnames=fields)\n","    csv_writer.writeheader()\n","    csv_writer.writerows(all_emails)"]},{"cell_type":"code","execution_count":20,"metadata":{},"outputs":[],"source":["# import needed libraries\n","import numpy as np\n","import string\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","%matplotlib inline\n","import seaborn as sns\n","sns.set_style('darkgrid')\n","import email\n","import re\n","from datetime import datetime\n","from dateutil import tz\n","import networkx as nx\n","import nltk\n","import wordcloud\n","import plotly.express as px\n","from plotly import graph_objects as go\n","\n","# Machine learning and NLP libraries\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","from sklearn.preprocessing import normalize\n","from sklearn.cluster import KMeans\n","from sklearn.decomposition import TruncatedSVD\n","from sklearn import metrics\n","import scipy as sp\n","from nltk.tokenize import word_tokenize\n","from nltk.stem import PorterStemmer, WordNetLemmatizer"]},{"cell_type":"code","execution_count":21,"metadata":{},"outputs":[],"source":["# Sentiment Analysis\n","import vaderSentiment\n","from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n","from nrclex import NRCLex"]},{"cell_type":"markdown","metadata":{},"source":["Loading data"]},{"cell_type":"code","execution_count":22,"metadata":{},"outputs":[],"source":["df = pd.read_csv(r\"enron_emails.csv\")"]},{"cell_type":"code","execution_count":23,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>file</th>\n","      <th>message</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>/Users/liqi/Desktop/IND5003/5003grp/maildir/.D...</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>/Users/liqi/Desktop/IND5003/5003grp/maildir/ar...</td>\n","      <td>Message-ID: &lt;17334447.1075857585446.JavaMail.e...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>/Users/liqi/Desktop/IND5003/5003grp/maildir/ar...</td>\n","      <td>Message-ID: &lt;19171686.1075857585034.JavaMail.e...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>/Users/liqi/Desktop/IND5003/5003grp/maildir/ar...</td>\n","      <td>Message-ID: &lt;29887033.1075857630725.JavaMail.e...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>/Users/liqi/Desktop/IND5003/5003grp/maildir/ar...</td>\n","      <td>Message-ID: &lt;29084893.1075849630138.JavaMail.e...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                                file  \\\n","0  /Users/liqi/Desktop/IND5003/5003grp/maildir/.D...   \n","1  /Users/liqi/Desktop/IND5003/5003grp/maildir/ar...   \n","2  /Users/liqi/Desktop/IND5003/5003grp/maildir/ar...   \n","3  /Users/liqi/Desktop/IND5003/5003grp/maildir/ar...   \n","4  /Users/liqi/Desktop/IND5003/5003grp/maildir/ar...   \n","\n","                                             message  \n","0                                                NaN  \n","1  Message-ID: <17334447.1075857585446.JavaMail.e...  \n","2  Message-ID: <19171686.1075857585034.JavaMail.e...  \n","3  Message-ID: <29887033.1075857630725.JavaMail.e...  \n","4  Message-ID: <29084893.1075849630138.JavaMail.e...  "]},"execution_count":23,"metadata":{},"output_type":"execute_result"}],"source":["df.head()"]},{"cell_type":"code","execution_count":31,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 517403 entries, 0 to 517402\n","Data columns (total 11 columns):\n"," #   Column      Non-Null Count   Dtype \n","---  ------      --------------   ----- \n"," 0   file        517403 non-null  object\n"," 1   message     517403 non-null  object\n"," 2   Date        517401 non-null  object\n"," 3   From        517401 non-null  object\n"," 4   To          495554 non-null  object\n"," 5   Subject     517401 non-null  object\n"," 6   X-From      517372 non-null  object\n"," 7   X-To        517372 non-null  object\n"," 8   X-Folder    517372 non-null  object\n"," 9   X-Origin    517372 non-null  object\n"," 10  X-Filename  517372 non-null  object\n","dtypes: object(11)\n","memory usage: 43.4+ MB\n"]}],"source":["df.info()"]},{"cell_type":"markdown","metadata":{},"source":["Data cleaning and preparing"]},{"cell_type":"code","execution_count":28,"metadata":{},"outputs":[],"source":["# Write functions to extract mail headers and body\n","def extractmailitems(field, msg):\n","    elst = []\n","    \n","    for i, message in (msg.items()):\n","        e = email.message_from_string(message)\n","        elst.append(e.get(field))\n","       \n","    return elst"]},{"cell_type":"code","execution_count":30,"metadata":{},"outputs":[],"source":["columns = ['Date', 'From', 'To', 'Subject', 'X-From', 'X-To', 'X-Folder', 'X-Origin', 'X-Filename']\n","df['message'] = df['message'].astype(str)  # Convert messages to strings\n","for i in columns:\n","    df[i] = extractmailitems(i, df['message'])"]},{"cell_type":"code","execution_count":32,"metadata":{},"outputs":[],"source":["def body(col):\n","    bodycolumn = []\n","    for message in col.values:\n","        e = email.message_from_string(message)\n","        bodycolumn.append(e.get_payload())\n"," \n","    return bodycolumn\n","df['Body'] = body(df['message'])"]},{"cell_type":"code","execution_count":33,"metadata":{},"outputs":[],"source":["# extract emplyees' names from file column\n","def employees(files):\n","    employees = []\n","    for i, employee in files.items():\n","        employee = employee.split('/')[0]\n","        employees.append(employee)\n","    return employees\n","df['Employee'] = employees(df['file'])"]},{"cell_type":"code","execution_count":34,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>file</th>\n","      <th>message</th>\n","      <th>Date</th>\n","      <th>From</th>\n","      <th>To</th>\n","      <th>Subject</th>\n","      <th>X-From</th>\n","      <th>X-To</th>\n","      <th>X-Folder</th>\n","      <th>X-Origin</th>\n","      <th>X-Filename</th>\n","      <th>Body</th>\n","      <th>Employee</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>482313</th>\n","      <td>/Users/liqi/Desktop/IND5003/5003grp/maildir/ke...</td>\n","      <td>Message-ID: &lt;11621426.1075855427794.JavaMail.e...</td>\n","      <td>Thu, 20 Dec 2001 08:51:28 -0800 (PST)</td>\n","      <td>chris.behney@enron.com</td>\n","      <td>mark.pickering@enron.com</td>\n","      <td>RE: email problem</td>\n","      <td>Behney, Chris &lt;/O=ENRON/OU=NA/CN=RECIPIENTS/CN...</td>\n","      <td>Pickering, Mark &lt;/O=ENRON/OU=NA/CN=RECIPIENTS/...</td>\n","      <td>\\Steven_Kean_Jan2002\\Kean, Steven J.\\junk mail</td>\n","      <td>Kean-S</td>\n","      <td>skean (Non-Privileged).pst</td>\n","      <td>Steve is set to unlimited space now. He and hi...</td>\n","      <td></td>\n","    </tr>\n","    <tr>\n","      <th>291686</th>\n","      <td>/Users/liqi/Desktop/IND5003/5003grp/maildir/ma...</td>\n","      <td>Message-ID: &lt;24481601.1075845583729.JavaMail.e...</td>\n","      <td>Tue, 18 Jul 2000 08:32:00 -0700 (PDT)</td>\n","      <td>aduncan@kilstock.com</td>\n","      <td>jeffrey.m.keenan@enron.com</td>\n","      <td>CPCN and followup</td>\n","      <td>\"Duncan, Allyson\" &lt;aduncan@kilstock.com&gt;</td>\n","      <td>\"'Keenan Jeffrey'\" &lt;Jeffrey.M.Keenan@enron.com&gt;</td>\n","      <td>\\Kay_Mann_June2001_1\\Notes Folders\\All documents</td>\n","      <td>MANN-K</td>\n","      <td>kmann.nsf</td>\n","      <td>Jeffrey, after our discussion yesterday regard...</td>\n","      <td></td>\n","    </tr>\n","    <tr>\n","      <th>35680</th>\n","      <td>/Users/liqi/Desktop/IND5003/5003grp/maildir/ka...</td>\n","      <td>Message-ID: &lt;25824784.1075856373727.JavaMail.e...</td>\n","      <td>Mon, 27 Nov 2000 03:34:00 -0800 (PST)</td>\n","      <td>vince.kaminski@enron.com</td>\n","      <td>vkaminski@aol.com</td>\n","      <td>Btu Weekly</td>\n","      <td>Vince J Kaminski</td>\n","      <td>vkaminski@aol.com</td>\n","      <td>\\Vincent_Kaminski_Jun2001_2\\Notes Folders\\Disc...</td>\n","      <td>Kaminski-V</td>\n","      <td>vkamins.nsf</td>\n","      <td>---------------------- Forwarded by Vince J Ka...</td>\n","      <td></td>\n","    </tr>\n","    <tr>\n","      <th>488574</th>\n","      <td>/Users/liqi/Desktop/IND5003/5003grp/maildir/ke...</td>\n","      <td>Message-ID: &lt;30286700.1075846190439.JavaMail.e...</td>\n","      <td>Wed, 8 Nov 2000 01:16:00 -0800 (PST)</td>\n","      <td>steven.kean@enron.com</td>\n","      <td>maureen.mcvicker@enron.com</td>\n","      <td>Order issued by FERC , EL00-95-000</td>\n","      <td>Steven J Kean</td>\n","      <td>Maureen McVicker</td>\n","      <td>\\Steven_Kean_Dec2000_1\\Notes Folders\\All docum...</td>\n","      <td>KEAN-S</td>\n","      <td>skean.nsf</td>\n","      <td>print\\n----- Forwarded by Steven J Kean/NA/Enr...</td>\n","      <td></td>\n","    </tr>\n","    <tr>\n","      <th>121540</th>\n","      <td>/Users/liqi/Desktop/IND5003/5003grp/maildir/ri...</td>\n","      <td>Message-ID: &lt;29790296.1075858647879.JavaMail.e...</td>\n","      <td>Mon, 22 Oct 2001 21:00:26 -0700 (PDT)</td>\n","      <td>no.address@enron.com</td>\n","      <td>None</td>\n","      <td>New Link for All-Employee Meeting</td>\n","      <td>Public Relations@ENRON</td>\n","      <td>All Enron Worldwide@ENRON</td>\n","      <td>\\RRING (Non-Privileged)\\Deleted Items</td>\n","      <td>Ring-R</td>\n","      <td>RRING (Non-Privileged)1.pst</td>\n","      <td>Attached is a new link for employees unable to...</td>\n","      <td></td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                                     file  \\\n","482313  /Users/liqi/Desktop/IND5003/5003grp/maildir/ke...   \n","291686  /Users/liqi/Desktop/IND5003/5003grp/maildir/ma...   \n","35680   /Users/liqi/Desktop/IND5003/5003grp/maildir/ka...   \n","488574  /Users/liqi/Desktop/IND5003/5003grp/maildir/ke...   \n","121540  /Users/liqi/Desktop/IND5003/5003grp/maildir/ri...   \n","\n","                                                  message  \\\n","482313  Message-ID: <11621426.1075855427794.JavaMail.e...   \n","291686  Message-ID: <24481601.1075845583729.JavaMail.e...   \n","35680   Message-ID: <25824784.1075856373727.JavaMail.e...   \n","488574  Message-ID: <30286700.1075846190439.JavaMail.e...   \n","121540  Message-ID: <29790296.1075858647879.JavaMail.e...   \n","\n","                                         Date                      From  \\\n","482313  Thu, 20 Dec 2001 08:51:28 -0800 (PST)    chris.behney@enron.com   \n","291686  Tue, 18 Jul 2000 08:32:00 -0700 (PDT)      aduncan@kilstock.com   \n","35680   Mon, 27 Nov 2000 03:34:00 -0800 (PST)  vince.kaminski@enron.com   \n","488574   Wed, 8 Nov 2000 01:16:00 -0800 (PST)     steven.kean@enron.com   \n","121540  Mon, 22 Oct 2001 21:00:26 -0700 (PDT)      no.address@enron.com   \n","\n","                                To                             Subject  \\\n","482313    mark.pickering@enron.com                   RE: email problem   \n","291686  jeffrey.m.keenan@enron.com                   CPCN and followup   \n","35680            vkaminski@aol.com                          Btu Weekly   \n","488574  maureen.mcvicker@enron.com  Order issued by FERC , EL00-95-000   \n","121540                        None   New Link for All-Employee Meeting   \n","\n","                                                   X-From  \\\n","482313  Behney, Chris </O=ENRON/OU=NA/CN=RECIPIENTS/CN...   \n","291686           \"Duncan, Allyson\" <aduncan@kilstock.com>   \n","35680                                    Vince J Kaminski   \n","488574                                      Steven J Kean   \n","121540                             Public Relations@ENRON   \n","\n","                                                     X-To  \\\n","482313  Pickering, Mark </O=ENRON/OU=NA/CN=RECIPIENTS/...   \n","291686    \"'Keenan Jeffrey'\" <Jeffrey.M.Keenan@enron.com>   \n","35680                                   vkaminski@aol.com   \n","488574                                   Maureen McVicker   \n","121540                          All Enron Worldwide@ENRON   \n","\n","                                                 X-Folder    X-Origin  \\\n","482313     \\Steven_Kean_Jan2002\\Kean, Steven J.\\junk mail      Kean-S   \n","291686   \\Kay_Mann_June2001_1\\Notes Folders\\All documents      MANN-K   \n","35680   \\Vincent_Kaminski_Jun2001_2\\Notes Folders\\Disc...  Kaminski-V   \n","488574  \\Steven_Kean_Dec2000_1\\Notes Folders\\All docum...      KEAN-S   \n","121540              \\RRING (Non-Privileged)\\Deleted Items      Ring-R   \n","\n","                         X-Filename  \\\n","482313   skean (Non-Privileged).pst   \n","291686                    kmann.nsf   \n","35680                   vkamins.nsf   \n","488574                    skean.nsf   \n","121540  RRING (Non-Privileged)1.pst   \n","\n","                                                     Body Employee  \n","482313  Steve is set to unlimited space now. He and hi...           \n","291686  Jeffrey, after our discussion yesterday regard...           \n","35680   ---------------------- Forwarded by Vince J Ka...           \n","488574  print\\n----- Forwarded by Steven J Kean/NA/Enr...           \n","121540  Attached is a new link for employees unable to...           "]},"execution_count":34,"metadata":{},"output_type":"execute_result"}],"source":["df.sample(5)"]},{"cell_type":"code","execution_count":35,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Date</th>\n","      <th>From</th>\n","      <th>To</th>\n","      <th>Subject</th>\n","      <th>X-From</th>\n","      <th>X-To</th>\n","      <th>X-Folder</th>\n","      <th>X-Origin</th>\n","      <th>X-Filename</th>\n","      <th>Body</th>\n","      <th>Employee</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>357946</th>\n","      <td>Mon, 26 Nov 2001 13:44:15 -0800 (PST)</td>\n","      <td>djcustomclips@djinteractive.com</td>\n","      <td>1529@wctopics.djnr.com</td>\n","      <td>Enron Corp.: CORRECT:Enron Employees' Lawyer B...</td>\n","      <td>djcustomclips@djinteractive.com</td>\n","      <td>1529@WCTOPICS.djnr.com</td>\n","      <td>\\RSHAPIRO (Non-Privileged)\\Shapiro, Richard\\De...</td>\n","      <td>Shapiro-R</td>\n","      <td>RSHAPIRO (Non-Privileged).pst</td>\n","      <td>CORRECT:Enron Employees' Lawyer Based In D.C.,...</td>\n","      <td></td>\n","    </tr>\n","    <tr>\n","      <th>36793</th>\n","      <td>Tue, 22 Feb 2000 18:37:00 -0800 (PST)</td>\n","      <td>vince.kaminski@enron.com</td>\n","      <td>vkaminski@aol.com</td>\n","      <td>March 2, NYMEX night at the rodeo</td>\n","      <td>Vince J Kaminski</td>\n","      <td>vkaminski@aol.com</td>\n","      <td>\\Vincent_Kaminski_Jun2001_7\\Notes Folders\\Disc...</td>\n","      <td>Kaminski-V</td>\n","      <td>vkamins.nsf</td>\n","      <td>---------------------- Forwarded by Vince J Ka...</td>\n","      <td></td>\n","    </tr>\n","    <tr>\n","      <th>481673</th>\n","      <td>Tue, 26 Sep 2000 06:32:00 -0700 (PDT)</td>\n","      <td>maureen.mcvicker@enron.com</td>\n","      <td>katherine.brown@enron.com</td>\n","      <td>Re: EXECUTIVE COMMITTEE MEETING - MONDAY, OCTO...</td>\n","      <td>Maureen McVicker</td>\n","      <td>Katherine Brown</td>\n","      <td>\\Steven_Kean_Dec2000_1\\Notes Folders\\Archiving...</td>\n","      <td>KEAN-S</td>\n","      <td>skean.nsf</td>\n","      <td>STEVE KEAN\\n\\n\\n\\n\\n\\n\\tKatherine Brown\\n\\t09/...</td>\n","      <td></td>\n","    </tr>\n","    <tr>\n","      <th>5315</th>\n","      <td>Tue, 20 Nov 2001 13:47:13 -0800 (PST)</td>\n","      <td>scott.tholan@enron.com</td>\n","      <td>john.lavorato@enron.com</td>\n","      <td>Resend - Competitive Analysis</td>\n","      <td>Tholan, Scott &lt;/O=ENRON/OU=NA/CN=RECIPIENTS/CN...</td>\n","      <td>Lavorato, John &lt;/O=ENRON/OU=NA/CN=RECIPIENTS/C...</td>\n","      <td>\\JLAVORA (Non-Privileged)\\Lavorato, John\\Delet...</td>\n","      <td>Lavorato-J</td>\n","      <td>JLAVORA (Non-Privileged).pst</td>\n","      <td>John,\\nAttached is my prioritized recommendati...</td>\n","      <td></td>\n","    </tr>\n","    <tr>\n","      <th>233697</th>\n","      <td>Fri, 19 Oct 2001 13:51:20 -0700 (PDT)</td>\n","      <td>mark.whitt@enron.com</td>\n","      <td>steve.walton@enron.com, paul.kaufman@enron.com...</td>\n","      <td>Buffalo Power Company LLC - Gas Turbine Power ...</td>\n","      <td>Whitt, Mark &lt;/O=ENRON/OU=NA/CN=RECIPIENTS/CN=M...</td>\n","      <td>Walton, Steve &lt;/O=ENRON/OU=NA/CN=RECIPIENTS/CN...</td>\n","      <td>\\BTYCHOL (Non-Privileged)\\Tycholiz, Barry\\Dele...</td>\n","      <td>TYCHOLIZ-B</td>\n","      <td>BTYCHOL (Non-Privileged).pst</td>\n","      <td>ENA and Crestone (Northern Border's non-regula...</td>\n","      <td></td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                         Date  \\\n","357946  Mon, 26 Nov 2001 13:44:15 -0800 (PST)   \n","36793   Tue, 22 Feb 2000 18:37:00 -0800 (PST)   \n","481673  Tue, 26 Sep 2000 06:32:00 -0700 (PDT)   \n","5315    Tue, 20 Nov 2001 13:47:13 -0800 (PST)   \n","233697  Fri, 19 Oct 2001 13:51:20 -0700 (PDT)   \n","\n","                                   From  \\\n","357946  djcustomclips@djinteractive.com   \n","36793          vince.kaminski@enron.com   \n","481673       maureen.mcvicker@enron.com   \n","5315             scott.tholan@enron.com   \n","233697             mark.whitt@enron.com   \n","\n","                                                       To  \\\n","357946                             1529@wctopics.djnr.com   \n","36793                                   vkaminski@aol.com   \n","481673                          katherine.brown@enron.com   \n","5315                              john.lavorato@enron.com   \n","233697  steve.walton@enron.com, paul.kaufman@enron.com...   \n","\n","                                                  Subject  \\\n","357946  Enron Corp.: CORRECT:Enron Employees' Lawyer B...   \n","36793                   March 2, NYMEX night at the rodeo   \n","481673  Re: EXECUTIVE COMMITTEE MEETING - MONDAY, OCTO...   \n","5315                        Resend - Competitive Analysis   \n","233697  Buffalo Power Company LLC - Gas Turbine Power ...   \n","\n","                                                   X-From  \\\n","357946                    djcustomclips@djinteractive.com   \n","36793                                    Vince J Kaminski   \n","481673                                   Maureen McVicker   \n","5315    Tholan, Scott </O=ENRON/OU=NA/CN=RECIPIENTS/CN...   \n","233697  Whitt, Mark </O=ENRON/OU=NA/CN=RECIPIENTS/CN=M...   \n","\n","                                                     X-To  \\\n","357946                             1529@WCTOPICS.djnr.com   \n","36793                                   vkaminski@aol.com   \n","481673                                    Katherine Brown   \n","5315    Lavorato, John </O=ENRON/OU=NA/CN=RECIPIENTS/C...   \n","233697  Walton, Steve </O=ENRON/OU=NA/CN=RECIPIENTS/CN...   \n","\n","                                                 X-Folder    X-Origin  \\\n","357946  \\RSHAPIRO (Non-Privileged)\\Shapiro, Richard\\De...   Shapiro-R   \n","36793   \\Vincent_Kaminski_Jun2001_7\\Notes Folders\\Disc...  Kaminski-V   \n","481673  \\Steven_Kean_Dec2000_1\\Notes Folders\\Archiving...      KEAN-S   \n","5315    \\JLAVORA (Non-Privileged)\\Lavorato, John\\Delet...  Lavorato-J   \n","233697  \\BTYCHOL (Non-Privileged)\\Tycholiz, Barry\\Dele...  TYCHOLIZ-B   \n","\n","                           X-Filename  \\\n","357946  RSHAPIRO (Non-Privileged).pst   \n","36793                     vkamins.nsf   \n","481673                      skean.nsf   \n","5315     JLAVORA (Non-Privileged).pst   \n","233697   BTYCHOL (Non-Privileged).pst   \n","\n","                                                     Body Employee  \n","357946  CORRECT:Enron Employees' Lawyer Based In D.C.,...           \n","36793   ---------------------- Forwarded by Vince J Ka...           \n","481673  STEVE KEAN\\n\\n\\n\\n\\n\\n\\tKatherine Brown\\n\\t09/...           \n","5315    John,\\nAttached is my prioritized recommendati...           \n","233697  ENA and Crestone (Northern Border's non-regula...           "]},"execution_count":35,"metadata":{},"output_type":"execute_result"}],"source":["# drop unimportant data columns and empty cells\n","df.drop(columns = ['file', 'message'], inplace=True)\n","df.dropna(axis = 0, inplace=True)\n","df.sample(5)"]},{"cell_type":"code","execution_count":36,"metadata":{},"outputs":[{"data":{"text/plain":["Employee\n","    495547\n","Name: count, dtype: int64"]},"execution_count":36,"metadata":{},"output_type":"execute_result"}],"source":["df.Employee.value_counts()[:20]"]},{"cell_type":"code","execution_count":37,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["/var/folders/k8/13s2hdrn4j3c1707gnj300r80000gn/T/ipykernel_45039/2007279768.py:2: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n","  df['Date'] = pd.to_datetime(df['Date'], utc = True, dayfirst = True)\n"]}],"source":["# changing the date format and type from string to date object\n","df['Date'] = pd.to_datetime(df['Date'], utc = True, dayfirst = True)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# creating a year column from the date column\n","df['Year'] = pd.DatetimeIndex(df['Date']).year"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["df.Year.value_counts()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# a function for cleaning text in columns\n","\n","def extract(col):\n","    regcol = []\n","    for sent in col.values:\n","        \n","        if str(sent).startswith('<'):  \n","            reg = re.split(r'@|\\(', str(sent))[0]\n","            reg = re.findall(r'[a-zA-Z]+\\'?-?', str(reg))           \n","            \n","        elif re.match(r'^\\d+', str(sent)):\n","            reg = re.split(r'@|\\(', str(sent))[0]\n","            reg = re.findall(r'[0-9]+\\'?-?', str(reg))\n","           \n","        else:\n","            reg = re.split(r'@|<|\\(', str(sent))[0]\n","            reg = re.findall(r'[a-zA-Z]+\\'?-?', str(reg))\n","            \n","        reg = re.sub(r'[\\'\\\",]', '', str(reg))\n","        regcol.append(str(reg.strip('[]')))\n","           \n","            \n","    return regcol"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["df['X-From'] = extract(df['X-From'])\n","df['X-To'] = extract(df['X-To'])"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["df['X-From'].value_counts()[:20]"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["df['X-To'].value_counts()[:20]"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["df.sample(5)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["df.info()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# make a diagram to show the count of messages sent per year\n","ax = df.groupby(df.Year)['X-Origin'].count().plot(figsize = (8,6))\n","ax.set_xlim(1995,2005)\n","ax.set_xlabel('Year', fontsize = 16)\n","ax.set_ylabel('Count', fontsize = 16)\n","ax.set_title('Messages sent across the years', fontsize = 16)\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# diagram for showing top senders\n","plt.figure(figsize = (16,10))\n","ax = sns.barplot(x = df['X-Origin'].value_counts().values[:30], y = df['X-Origin'].value_counts().keys()[:30] ,palette = 'rocket', orient = 'h')\n","ax.set_xlabel('Count', fontsize = 18)\n","ax.set_ylabel('Original Senders', fontsize = 18)\n","ax.set_title('Top 30 Senders', fontsize = 20)\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# diagram showing top recepients\n","plt.figure(figsize = (16,10))\n","ax = sns.barplot(x = df['To'].value_counts().values[:30], y = df['To'].value_counts().keys()[:30] ,palette = 'crest', orient = 'h')\n","ax.set_xlabel('Count', fontsize = 18)\n","ax.set_ylabel('Recepient E-Mail', fontsize = 18)\n","ax.set_title('Top 30 Recepient E-Mails', fontsize = 20)\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["userlist = df['X-Origin'].unique()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["useryears = []\n","for user in userlist:\n","    year = df.loc[df['X-Origin'] == user, 'Year'].iloc[0]\n","    useryears.append(year)\n","    useryears"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["usercount = []\n","counter = 0\n","for name in userlist:\n","    for user in df['X-Origin'].values:\n","        if user == name:\n","            counter += 1\n","    usercount.append(counter)\n","    counter = 0"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["dataf = sorted(list(zip(userlist, usercount, useryears)), key= lambda user: user[1], reverse = True)[:30]"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["dataf = pd.DataFrame(dataf)\n","dataf.columns = ['User', 'Count', 'Year']\n","dataf.head()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# diagram showing top users and count of mails sent per year\n","plt.figure(figsize = (20,16))\n","ax = sns.barplot(data = dataf, x ='User', y = 'Count', hue = 'Year', palette = 'viridis' , saturation = 0.7, width = 1.5)\n","sns.despine()\n","plt.xlabel('User', fontsize = 18)\n","plt.ylabel('Count', fontsize = 18)\n","plt.title('User sent mails/year', fontsize = 22)\n","plt.xticks(rotation = 45, fontsize = 12)\n","plt.yticks(fontsize = 12)\n","plt.legend(fontsize = 14)\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# a network of first 2500 rows showing the network of Allen P\n","plt.figure(figsize = (20, 20))\n","G = nx.from_pandas_edgelist(df[:2500], 'X-Origin', 'X-To')\n","pos = nx.draw_random(G, node_size = 50, node_color = 'blue', edge_color = 'salmon', with_labels = True)\n","plt.title('Network of Emails (First 2500)', fontsize = 24)\n","plt.show()"]},{"cell_type":"markdown","metadata":{},"source":["**Machine Learning and NLP on the dataset**"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["stopwords = nltk.corpus.stopwords.words('english')\n","newstopwords = ['Re', 'FW', 'Fwd', 'EOL', 'E', 'mail', 'PLEASE', 'Ahead']\n","for i in newstopwords:\n","    stopwords.append(i)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["subjects = ' '.join(df['Subject'].values)\n","fig, ax = plt.subplots(figsize=(14, 10))\n","wc = wordcloud.WordCloud(width = 800, height = 600, max_words = 200, stopwords = stopwords).generate(subjects)\n","ax.imshow(wc)\n","plt.axis('off')\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["content = ' '.join(df['Body'].sample(5000).values)\n","fig, ax = plt.subplots(figsize=(14, 10))\n","wc = wordcloud.WordCloud(width = 800, height = 600, max_words = 300, stopwords = stopwords).generate(content)\n","ax.imshow(wc)\n","plt.axis('off')\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["nltk.download('wordnet')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["nltk.download('punkt')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["!unzip /usr/share/nltk_data/corpora/wordnet.zip -d /usr/share/nltk_data/corpora/"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# function for cleaning the body text\n","def cleaningbody(col):\n","    msgcol = []\n","    for msg in col.values:\n","        msg = re.sub(r'[<>\\n+\\t+\\s+\\*]', ' ', msg)\n","        msg = re.sub(r'[0-9]+[a-zA-Z]+\\d+[?!].DOC', ' ', msg)\n","        msg = re.sub(r'[?\\s+\\-+\\s+?_=~]', ' ', msg)\n","        msg = re.sub(r' +', ' ', msg)\n","        msg = msg.lower().strip(' ')\n","        msgcol.append(msg)\n","    return msgcol\n","df['Body'] = cleaningbody(df['Body'])"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# preparing the lemmatization function\n","lemmatizer = WordNetLemmatizer()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Tokenizing and lemmatizing the text to prepare for classification and sentiment analysis\n","text = []\n","for msg in df['Body'].values:\n","    msg_tokens = word_tokenize(msg)\n","    msg_tokens = [token.lower() for token in msg_tokens if token.isalpha()]\n","    msg_tokens = [word for word in msg_tokens if not word in stopwords]\n","    msg_tokens = [lemmatizer.lemmatize(word) for word in msg_tokens]\n","    \n","    text.append(msg_tokens)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["text = [' '.join(message) for message in text]"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# vectorizing the data using Tfidfvectorizer\n","vectorizer = TfidfVectorizer(min_df = 5, max_features = 5000, stop_words = stopwords, norm = 'l1')\n","data = vectorizer.fit_transform(text)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Normalizing the data\n","data_norm = normalize(data)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["print(data_norm.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Decomposition of the data and decreasing alot of features\n","svd = TruncatedSVD(n_components = 2, n_iter = 10, random_state = 42)\n","datasvd = svd.fit_transform(data_norm)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["datasvd.shape"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Use the Elbow method to define the optimal number of clusters for kmeans clustering\n","max_iter = 1000\n","sumsquares = []\n","number_clusters = range(1,11)\n","for i in number_clusters:\n","    kmeans = KMeans(n_clusters = i, max_iter = max_iter, n_init = 'auto')\n","    kmeans.fit(datasvd)\n","    sumsquares.append(kmeans.inertia_)\n","plt.figure(figsize = (8,6))\n","plt.plot(number_clusters, sumsquares)\n","plt.xlabel('Clusters', fontsize = 14)\n","plt.ylabel('Sum of Squared Distances', fontsize = 14)\n","plt.title('Elbow Method', fontsize = 16)\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["n_clusters = 6\n","clf = KMeans(n_clusters = n_clusters,init = 'random', max_iter = max_iter, tol = 0.0001, algorithm = 'lloyd', n_init = 'auto', random_state = 42)\n","fittedkmeans = clf.fit_predict(datasvd)\n","centroids = clf.cluster_centers_"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# A diagram showing the clusters\n","plt.figure(figsize = (8,6))\n","plt.scatter(datasvd[:,0], datasvd[:,1], c = fittedkmeans, s = 50, cmap = 'viridis', alpha = 0.5)\n","plt.scatter(centroids[:, 0], centroids[:, 1], s = 150, c = 'black', alpha = 0.8)\n","plt.annotate('Cluster 0', xy = (centroids[0][0], centroids[0][1]), xytext = (centroids[0][0] + 0.02, centroids[0][1] + 0.03), color = 'white', fontsize = 12)\n","plt.annotate('Cluster 1', xy = (centroids[1][0], centroids[1][1]), xytext = (centroids[1][0] + 0.02, centroids[1][1] + 0.02), color = 'white', fontsize = 12)\n","plt.annotate('Cluster 2', xy = (centroids[2][0], centroids[2][1]), xytext = (centroids[2][0] - 0.05, centroids[2][1] - 0.06), color = 'white', fontsize = 12)\n","plt.annotate('Cluster 3', xy = (centroids[3][0], centroids[3][1]), xytext = (centroids[3][0] - 0.01, centroids[3][1] - 0.07), color = 'white', fontsize = 12)\n","plt.annotate('Cluster 4', xy = (centroids[4][0], centroids[4][1]), xytext = (centroids[4][0] - 0.03, centroids[4][1] + 0.04), color = 'white', fontsize = 12)\n","plt.annotate('Cluster 5', xy = (centroids[5][0], centroids[5][1]), xytext = (centroids[5][0] - 0.03, centroids[5][1] + 0.03), color = 'white', fontsize = 12)\n","\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# extract top words in every cluster using the inverse_transform method\n","original_space_centroids = svd.inverse_transform(kmeans.cluster_centers_)\n","order_centroids = original_space_centroids.argsort()[:, ::-1] #(10,5000)\n","terms = vectorizer.get_feature_names_out()\n","\n","for i in range(n_clusters):\n","    print(f\"Cluster {i}: \", end=\"\")\n","    for ind in order_centroids[i, :20]:\n","        print(f\"{terms[ind]} \", end=\"\")\n","        \n","    print()"]},{"cell_type":"markdown","metadata":{},"source":["***Sentiment Analysis***"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# praeparing the sentiment analyzer\n","analyzer = SentimentIntensityAnalyzer()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["df['sentiment scores'] = [analyzer.polarity_scores(message) for message in text]\n","df.sample(5)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Determine the positive and negative scores\n","sentiment = []\n","for i in df['sentiment scores'].values:\n","    if i['compound'] > 0.05:\n","        sentiment.append('Positive')\n","    elif i['compound'] < 0.05:\n","        sentiment.append('Negative')\n","    else:\n","        sentiment.append('Neutral')\n","df['Sentiment'] = sentiment"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["sentiment_values = df['Sentiment'].value_counts()\n","sentiment_values"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# a graph for the sentiment as a funnel shaped graph\n","fig = px.funnel(sentiment_values)\n","fig.show()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# defining another function for sentiment analysis with different emotions using NRCLex lexicon\n","def sentiment(message):\n","    text = NRCLex(message)\n","    if text.top_emotions[0][1] == 0.0:\n","        return 'No Emotion'\n","    else:\n","        return text.top_emotions[0][0]\n","df['Emotions'] =  df['Body'].apply(sentiment)\n","df.sample(5)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["emotions = df['Emotions'].value_counts()\n","emotion_chart = pd.DataFrame(emotions)\n","emotion_chart = emotion_chart.drop('No Emotion', axis = 0)\n","emotion_chart"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# A pie chart for showing the percentage of every emotion in the text\n","labels = emotion_chart.index.tolist()\n","plt.figure(figsize = (11,11))\n","plt.pie(emotion_chart['Emotions'].values, labels = labels , autopct = '%1.1f%%', labeldistance= 1.1)\n","plt.title('Emotions', fontsize = 14)\n","plt.legend(loc = 'upper right')\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"base","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.8"}},"nbformat":4,"nbformat_minor":2}
