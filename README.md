# 5003_enron_emails_nlper

To begin, run the code in the file ***Data_Preprocessing_Visu.ipynb***, which handles downloading and preprocessing for the ***Enron Email dataset***. Once the dataset is cleaned and preprocessed, you can proceed with either the ***ML_NLP_classification.ipynb*** or ***Sentiment_Analysis.ipynb*** file. These files address different tasks, performing anomaly detection and sentiment analysis separately.

## Data_Preprocessing_Visu.ipynb
### 1. Database download

In order to download the database, run the first cell in jupter notebook, the database will download
```python
import requests
url = "https://www.cs.cmu.edu/~./enron/enron_mail_20150507.tar.gz"
filename = "../enron_mail_20150507.tar.gz"
with open(filename, "wb") as f:
    r = requests.get(url)
    f.write(r.content)
```
and unzip automatically.
```python
print("Unzipping Enron dataset (This may take a while)")
import tarfile
tfile = tarfile.open("../enron_mail_20150507.tar.gz")
tfile.extractall(".")
tfile.close()
```
After downloading the database, it will show "You're ready to go!", which named "maildir".

You can make this cell to command after you download the database successfully.

### 2. Convert Enron database to .csv file

Read files' content in maildir files, and create a .csv file named "enron_emails.csv".

The .csv file will contain two columns -- "file", "message"

1. file: store the directly name of file
2. message: store the content of the email that we read from file

After run the cell to read the files and write into .csv file, a "enron_emails.csv" will be autogenerated under the same folder of our raw database.

**_The "enron_emails.csv" file will be automatically saved into parent folder_**

### 3. Data Preprocessing

After data cleaning and preprocessing, it will generate a new csv file called "enron_emails_cleaned.csv", both ML_NLP_classification and Sentiment Analysis have to first import this cleaned enron email datasets into code then proceeded to next procedure.

## ML_NLP_Classification

### 1. Data Import and Sorting: 

The code uses pandas and numpy to handle the data. Initially, it reads the data from a CSV file and then sorts it by " the sender (From) ", " receiver (To) ", and " date (Date) ". This sorting is necessary for calculating the time intervals between consecutive emails from the same sender to the same receiver.

### 2. Feature Engineering:

Time Interval Calculation: It calculates the time difference between consecutive emails from the same sender to the same receiver using ***groupby(['From', 'To'])['Date'].diff().dt.total_seconds()***. This value is stored in seconds.
Email Content Size: The length of the email content is calculated and used as a feature representing email size.
Subject Length: The code also computes the length of each emailâ€™s subject line to add as a feature.

### 3. Saving the Enriched Data: 

The enriched DataFrame, which now includes features like time interval, email size, and subject length, is saved to a new CSV file, ***../enriched_emails.csv***. This file allows for further analysis with additional email characteristics.

## Data Visualization 

All Graphs are saved in ***Graphs for Data Visualization*** file as part of results of our project, for easy arranging. 

## File Structure:
<img width="354" alt="image" src="https://github.com/user-attachments/assets/30427d38-c589-4f83-8289-a94833818c63">




